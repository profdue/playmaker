# prediction_engine.py - PROFESSIONAL GRADE FIXED VERSION
import numpy as np
import pandas as pd
from scipy.stats import poisson, skellam, norm
from typing import Dict, Any, Tuple, List, Optional
import math
from dataclasses import dataclass
import logging
from datetime import datetime
import warnings
from enum import Enum
import json

warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# =============================================================================
# PROFESSIONAL PARAMETERS - EVIDENCE-BASED ONLY
# =============================================================================

LEAGUE_PARAMS = {
    'premier_league': {
        'away_penalty': 1.00,
        'goal_intensity': 'high',
        'volatility': 'medium',
        'min_edge': 0.08
    },
    'la_liga': {
        'away_penalty': 0.98,
        'goal_intensity': 'medium', 
        'volatility': 'low',
        'min_edge': 0.06
    },
    'serie_a': {
        'away_penalty': 0.97,
        'goal_intensity': 'low',
        'volatility': 'medium_low', 
        'min_edge': 0.10
    },
    'bundesliga': {
        'away_penalty': 1.02,
        'goal_intensity': 'very_high',
        'volatility': 'high',
        'min_edge': 0.07
    },
    'ligue_1': {
        'away_penalty': 0.98,
        'goal_intensity': 'low',
        'volatility': 'medium',
        'min_edge': 0.08
    },
    'eredivisie': {
        'away_penalty': 1.00,
        'goal_intensity': 'high',
        'volatility': 'high',
        'min_edge': 0.12
    },
    'liga_portugal': {
        'away_penalty': 0.96,
        'goal_intensity': 'medium',
        'volatility': 'medium',
        'min_edge': 0.09
    },
    'championship': {
        'away_penalty': 0.92,
        'goal_intensity': 'medium_low',
        'volatility': 'very_high',
        'min_edge': 0.15
    },
    'default': {
        'away_penalty': 1.00,
        'goal_intensity': 'medium',
        'volatility': 'medium',
        'min_edge': 0.10
    }
}

# Volatility-based stake multipliers
VOLATILITY_MULTIPLIERS = {
    'low': 1.2,
    'medium_low': 1.1, 
    'medium': 1.0,
    'high': 0.8,
    'very_high': 0.6
}

# Goal intensity adjustments for total goals calibration
GOAL_INTENSITY_ADJUSTMENTS = {
    'very_low': 0.90,
    'low': 0.94,
    'medium': 1.00,
    'medium_high': 1.02,
    'high': 1.04,
    'very_high': 1.08
}

@dataclass
class MatchContext:
    """Professional match context - DESCRIPTIVE ONLY"""
    primary_pattern: str
    quality_gap: str
    home_advantage_amplified: bool = False
    away_scoring_issues: bool = False
    expected_tempo: str = "medium"
    confidence_score: float = 0.0

@dataclass  
class MonteCarloResults:
    """Professional Monte Carlo results with uncertainty"""
    home_win_prob: float
    draw_prob: float
    away_win_prob: float
    over_25_prob: float
    btts_prob: float
    exact_scores: Dict[str, float]
    confidence_intervals: Dict[str, Tuple[float, float]]
    raw_home_xg: float
    raw_away_xg: float
    adjusted_home_xg: float
    adjusted_away_xg: float

@dataclass
class BettingRecommendation:
    """Professional betting recommendation with guardrails"""
    market: str
    model_prob: float
    market_odds: float
    implied_prob: float
    edge: float
    recommended_stake: float
    confidence: str
    robustness: str
    explanation: List[str]
    passes_sensitivity: bool

@dataclass
class ModelDiagnostics:
    """Comprehensive model diagnostics"""
    data_quality_score: float
    calibration_score: float
    market_alignment: float
    uncertainty_score: float
    sensitivity_passed: bool
    recommended_action: str

class ProfessionalXGCalculator:
    """Evidence-based xG calculation with uncertainty"""
    
    def __init__(self):
        self.injury_impact_map = {
            1: 0.02,  # Rotation player
            2: 0.05,  # Regular starter  
            3: 0.10,  # Key player
            4: 0.15,  # Star player
            5: 0.25   # Multiple key players
        }
        
        self.motivation_impact_map = {
            'Low': 0.95,
            'Normal': 1.00,
            'High': 1.05,
            'Very High': 1.08
        }
    
    def calculate_base_xg(self, goals: int, conceded: int, is_home: bool, league: str) -> Tuple[float, float]:
        """Calculate base xG with uncertainty"""
        # Base xG from goals scored and conceded
        attack_xg = max(0.3, goals / 6.0)
        defense_quality = max(0.3, 2.0 - (conceded / 6.0))  # Inverse of conceded
        
        # Apply home/away adjustment
        league_params = LEAGUE_PARAMS.get(league, LEAGUE_PARAMS['default'])
        if not is_home:
            attack_xg *= league_params['away_penalty']
        
        # Add uncertainty (10-15% of mean)
        uncertainty = attack_xg * 0.12
        
        return attack_xg, uncertainty
    
    def apply_context_factors(self, base_xg: float, uncertainty: float, injuries: int, 
                            motivation: str, recent_form: int) -> Tuple[float, float]:
        """Apply evidence-based context factors"""
        # Injury impact
        injury_factor = 1.0 - self.injury_impact_map.get(injuries, 0.05)
        
        # Motivation impact
        motivation_factor = self.motivation_impact_map.get(motivation, 1.0)
        
        # Recent form impact (modest)
        form_factor = 1.0 + (recent_form * 0.02)  # Max Â±6%
        
        # Apply factors
        adjusted_xg = base_xg * injury_factor * motivation_factor * form_factor
        adjusted_uncertainty = uncertainty * 1.1  # Slight increase for compounding factors
        
        return max(0.2, adjusted_xg), adjusted_uncertainty

class BivariatePoissonSimulator:
    """Professional bivariate Poisson simulator for correlated goals"""
    
    def __init__(self, n_simulations: int = 25000):
        self.n_simulations = n_simulations
    
    def simulate_match(self, home_xg: float, away_xg: float, home_uncertainty: float, 
                      away_uncertainty: float, correlation: float = 0.15) -> Tuple[np.ndarray, np.ndarray]:
        """
        Simulate match with bivariate Poisson and uncertainty propagation
        """
        # Sample from xG uncertainty distributions
        home_xg_samples = np.random.normal(home_xg, home_uncertainty, self.n_simulations)
        away_xg_samples = np.random.normal(away_xg, away_uncertainty, self.n_simulations)
        
        # Ensure positive xG values
        home_xg_samples = np.maximum(0.1, home_xg_samples)
        away_xg_samples = np.maximum(0.1, away_xg_samples)
        
        # Bivariate Poisson simulation with correlation
        lambda1 = home_xg_samples - correlation * np.minimum(home_xg_samples, away_xg_samples)
        lambda2 = away_xg_samples - correlation * np.minimum(home_xg_samples, away_xg_samples) 
        lambda3 = correlation * np.minimum(home_xg_samples, away_xg_samples)
        
        # Ensure positive lambdas
        lambda1 = np.maximum(0.05, lambda1)
        lambda2 = np.maximum(0.05, lambda2)
        lambda3 = np.maximum(0.0, lambda3)
        
        # Simulate goals
        C = np.random.poisson(lambda3)
        A = np.random.poisson(lambda1)
        B = np.random.poisson(lambda2)
        
        home_goals = A + C
        away_goals = B + C
        
        return home_goals, away_goals
    
    def calculate_probabilities(self, home_goals: np.ndarray, away_goals: np.ndarray, 
                              league: str) -> Dict[str, float]:
        """Calculate market probabilities from simulated goals"""
        
        # Match outcomes
        home_wins = np.mean(home_goals > away_goals)
        draws = np.mean(home_goals == away_goals)
        away_wins = np.mean(home_goals < away_goals)
        
        # Both teams to score
        btts_yes = np.mean((home_goals > 0) & (away_goals > 0))
        
        # Over/under markets
        total_goals = home_goals + away_goals
        over_15 = np.mean(total_goals > 1.5)
        over_25 = np.mean(total_goals > 2.5)
        over_35 = np.mean(total_goals > 3.5)
        
        # Exact scores (top 8)
        score_counts = {}
        for h, a in zip(home_goals[:10000], away_goals[:10000]):
            score = f"{h}-{a}"
            score_counts[score] = score_counts.get(score, 0) + 1
        
        exact_scores = {
            score: count/10000 
            for score, count in sorted(score_counts.items(), key=lambda x: x[1], reverse=True)[:8]
        }
        
        # League-specific calibration
        league_params = LEAGUE_PARAMS.get(league, LEAGUE_PARAMS['default'])
        goal_intensity = GOAL_INTENSITY_ADJUSTMENTS.get(league_params['goal_intensity'], 1.0)
        
        # Apply modest calibration
        over_25 = min(0.95, over_25 * goal_intensity)
        btts_yes = min(0.95, btts_yes * goal_intensity)
        
        return {
            'home_win': home_wins,
            'draw': draws,
            'away_win': away_wins,
            'btts_yes': btts_yes,
            'btts_no': 1 - btts_yes,
            'over_15': over_15,
            'over_25': over_25,
            'over_35': over_35,
            'under_25': 1 - over_25,
            'exact_scores': exact_scores
        }

class MarketAnalyzer:
    """Professional market analysis with proper vig removal"""
    
    def remove_vig_1x2(self, home_odds: float, draw_odds: float, away_odds: float) -> Dict[str, float]:
        """Remove vig from 1X2 market using proper normalization"""
        home_implied = 1.0 / home_odds
        draw_implied = 1.0 / draw_odds
        away_implied = 1.0 / away_odds
        
        total_implied = home_implied + draw_implied + away_implied
        overround = total_implied - 1.0
        
        # Normalize to remove vig
        home_prob = home_implied / total_implied
        draw_prob = draw_implied / total_implied
        away_prob = away_implied / total_implied
        
        return {
            'home': home_prob,
            'draw': draw_prob, 
            'away': away_prob,
            'overround': overround
        }
    
    def remove_vig_two_way(self, yes_odds: float, no_odds: float) -> Dict[str, float]:
        """Remove vig from two-way markets (BTTS, O/U)"""
        yes_implied = 1.0 / yes_odds
        no_implied = 1.0 / no_odds
        
        total_implied = yes_implied + no_implied
        overround = total_implied - 1.0
        
        # Normalize to remove vig
        yes_prob = yes_implied / total_implied
        no_prob = no_implied / total_implied
        
        return {
            'yes': yes_prob,
            'no': no_prob,
            'overround': overround
        }
    
    def calculate_edges(self, model_probs: Dict[str, float], market_odds: Dict[str, float]) -> Dict[str, float]:
        """Calculate proper edges with vig removal"""
        
        # 1X2 edges
        vig_removed_1x2 = self.remove_vig_1x2(
            market_odds.get('1x2_home', 2.0),
            market_odds.get('1x2_draw', 3.0), 
            market_odds.get('1x2_away', 3.0)
        )
        
        edges_1x2 = {
            'home_win': model_probs['home_win'] - vig_removed_1x2['home'],
            'draw': model_probs['draw'] - vig_removed_1x2['draw'],
            'away_win': model_probs['away_win'] - vig_removed_1x2['away']
        }
        
        # BTTS edges
        vig_removed_btts = self.remove_vig_two_way(
            market_odds.get('btts_yes', 2.0),
            market_odds.get('btts_no', 1.8)
        )
        
        edges_btts = {
            'btts_yes': model_probs['btts_yes'] - vig_removed_btts['yes'],
            'btts_no': model_probs['btts_no'] - vig_removed_btts['no']
        }
        
        # Over/under edges
        vig_removed_over_under = self.remove_vig_two_way(
            market_odds.get('over_25', 2.0),
            market_odds.get('under_25', 1.8)
        )
        
        edges_ou = {
            'over_25': model_probs['over_25'] - vig_removed_over_under['yes'],
            'under_25': model_probs['under_25'] - vig_removed_over_under['no']
        }
        
        return {**edges_1x2, **edges_btts, **edges_ou}

class SensitivityAnalyzer:
    """Professional sensitivity analysis for edge robustness"""
    
    def __init__(self):
        self.sensitivity_levels = [-0.20, -0.10, 0.0, 0.10, 0.20]
    
    def analyze_robustness(self, base_home_xg: float, base_away_xg: float, 
                          base_edges: Dict[str, float], league: str) -> Dict[str, Any]:
        """Analyze edge robustness to xG changes"""
        
        min_edge = LEAGUE_PARAMS.get(league, LEAGUE_PARAMS['default'])['min_edge']
        robust_edges = {}
        fragile_edges = {}
        
        for market, base_edge in base_edges.items():
            edge_survives = 0
            total_scenarios = 0
            
            for home_adj in self.sensitivity_levels:
                for away_adj in self.sensitivity_levels:
                    # Skip extreme simultaneous adjustments
                    if abs(home_adj) == 0.20 and abs(away_adj) == 0.20:
                        continue
                    
                    adjusted_home_xg = base_home_xg * (1 + home_adj)
                    adjusted_away_xg = base_away_xg * (1 + away_adj)
                    
                    # Simplified edge adjustment (in reality, you'd re-run simulation)
                    # This is a proxy - real implementation would re-run MC
                    edge_change = (home_adj + away_adj) * 0.3  # Approximation
                    adjusted_edge = base_edge - edge_change
                    
                    if abs(adjusted_edge) >= min_edge * 0.5:  # More lenient threshold
                        edge_survives += 1
                    total_scenarios += 1
            
            survival_rate = edge_survives / total_scenarios if total_scenarios > 0 else 0
            
            if survival_rate >= 0.7:  # 70% survival rate
                robust_edges[market] = {
                    'base_edge': base_edge,
                    'survival_rate': survival_rate,
                    'robustness': 'HIGH'
                }
            elif survival_rate >= 0.4:  # 40% survival rate
                robust_edges[market] = {
                    'base_edge': base_edge, 
                    'survival_rate': survival_rate,
                    'robustness': 'MEDIUM'
                }
            else:
                fragile_edges[market] = {
                    'base_edge': base_edge,
                    'survival_rate': survival_rate, 
                    'robustness': 'LOW'
                }
        
        return {
            'robust_edges': robust_edges,
            'fragile_edges': fragile_edges,
            'overall_robustness': 'HIGH' if len(robust_edges) >= len(fragile_edges) else 'LOW'
        }

class ProfessionalStakingCalculator:
    """Professional staking with proper risk management"""
    
    def __init__(self):
        self.volatility_multipliers = VOLATILITY_MULTIPLIERS
    
    def calculate_kelly_stake(self, model_prob: float, odds: float, bankroll: float, 
                            league: str, edge_robustness: str) -> float:
        """Calculate Kelly stake with multiple guardrails"""
        
        # Basic Kelly formula
        implied_prob = 1.0 / odds
        edge = model_prob - implied_prob
        kelly_fraction = edge / implied_prob if implied_prob > 0 else 0
        
        # Base stake
        base_stake = bankroll * kelly_fraction
        
        # Apply fractional Kelly (conservative)
        fractional_stake = base_stake * 0.2  # 20% Kelly
        
        # Volatility adjustment
        league_params = LEAGUE_PARAMS.get(league, LEAGUE_PARAMS['default'])
        volatility_multiplier = self.volatility_multipliers.get(league_params['volatility'], 1.0)
        volatility_stake = fractional_stake * volatility_multiplier
        
        # Robustness adjustment
        robustness_multiplier = {
            'HIGH': 1.0,
            'MEDIUM': 0.6, 
            'LOW': 0.3
        }.get(edge_robustness, 0.3)
        
        robustness_stake = volatility_stake * robustness_multiplier
        
        # Hard cap at 3% of bankroll
        final_stake = min(robustness_stake, bankroll * 0.03)
        
        # Minimum stake threshold
        if final_stake < bankroll * 0.005:  # 0.5% minimum
            return 0.0
        
        return final_stake

class MatchContextAnalyzer:
    """Professional context analysis - DESCRIPTIVE ONLY"""
    
    def analyze_context(self, home_xg: float, away_xg: float, home_tier: str, 
                       away_tier: str, home_recent: int, away_recent: int, 
                       league: str) -> MatchContext:
        """Analyze match context - NO NUMERICAL INFLUENCE"""
        
        total_xg = home_xg + away_xg
        xg_diff = home_xg - away_xg
        
        # Quality gap analysis
        tier_strength = {'ELITE': 4, 'STRONG': 3, 'MEDIUM': 2, 'WEAK': 1}
        home_strength = tier_strength.get(home_tier, 2)
        away_strength = tier_strength.get(away_tier, 2)
        strength_diff = abs(home_strength - away_strength)
        
        if strength_diff >= 3:
            quality_gap = "extreme"
        elif strength_diff >= 2:
            quality_gap = "significant" 
        elif strength_diff >= 1:
            quality_gap = "moderate"
        else:
            quality_gap = "even"
        
        # Primary pattern (descriptive only)
        if xg_diff >= 0.3 and quality_gap in ['significant', 'extreme']:
            primary_pattern = "home_dominance"
        elif xg_diff <= -0.3 and quality_gap in ['significant', 'extreme']:
            primary_pattern = "away_counter" 
        elif total_xg > 3.0:
            primary_pattern = "offensive_showdown"
        elif total_xg < 2.2:
            primary_pattern = "defensive_battle"
        elif abs(xg_diff) < 0.2:
            primary_pattern = "tactical_stalemate"
        else:
            primary_pattern = "balanced"
        
        # Context flags (descriptive only)
        home_advantage_amplified = (
            league == 'championship' and 
            home_recent >= 5 and 
            home_tier == 'WEAK' and 
            xg_diff > 0.2
        )
        
        away_scoring_issues = (
            away_recent <= 1 and 
            away_xg < 1.0
        )
        
        # Confidence score (descriptive only)
        confidence_score = self._calculate_confidence(
            total_xg, abs(xg_diff), strength_diff, home_recent, away_recent
        )
        
        return MatchContext(
            primary_pattern=primary_pattern,
            quality_gap=quality_gap,
            home_advantage_amplified=home_advantage_amplified,
            away_scoring_issues=away_scoring_issues,
            confidence_score=confidence_score
        )
    
    def _calculate_confidence(self, total_xg: float, xg_diff: float, strength_diff: int,
                            home_recent: int, away_recent: int) -> float:
        """Calculate descriptive confidence score"""
        confidence = 50.0  # Base
        
        # Total xG confidence
        if total_xg > 3.2 or total_xg < 2.2:
            confidence += 15
        elif total_xg > 2.8 or total_xg < 2.4:
            confidence += 8
            
        # xG difference confidence
        if xg_diff > 0.4:
            confidence += 12
        elif xg_diff > 0.2:
            confidence += 6
            
        # Quality gap confidence
        if strength_diff >= 2:
            confidence += 10
            
        # Recent form confidence
        form_confidence = min(20, (home_recent * 2) + (max(0, 3 - away_recent) * 3))
        confidence += form_confidence
        
        return min(95.0, confidence)

class ProfessionalPredictionEngine:
    """MAIN PROFESSIONAL PREDICTION ENGINE - FULLY FIXED"""
    
    def __init__(self, match_data: Dict[str, Any]):
        self.data = self._validate_data(match_data)
        self.xg_calculator = ProfessionalXGCalculator()
        self.simulator = BivariatePoissonSimulator()
        self.market_analyzer = MarketAnalyzer()
        self.sensitivity_analyzer = SensitivityAnalyzer()
        self.staking_calculator = ProfessionalStakingCalculator()
        self.context_analyzer = MatchContextAnalyzer()
        
        logger.info(f"Initialized professional engine for {self.data['home_team']} vs {self.data['away_team']}")
    
    def _validate_data(self, match_data: Dict[str, Any]) -> Dict[str, Any]:
        """Professional data validation"""
        validated_data = match_data.copy()
        
        # Required fields
        required = ['home_team', 'away_team', 'league']
        for field in required:
            if field not in validated_data:
                validated_data[field] = 'Unknown'
                
        # Default values for predictive fields
        predictive_defaults = {
            'home_goals': 8, 'away_goals': 4,
            'home_conceded': 6, 'away_conceded': 7, 
            'home_goals_home': 6, 'away_goals_away': 1,
            'home_injuries': 2, 'away_injuries': 2,
            'home_motivation': 'Normal', 'away_motivation': 'Normal'
        }
        
        for field, default in predictive_defaults.items():
            if field not in validated_data:
                validated_data[field] = default
            elif validated_data[field] is None:
                validated_data[field] = default
        
        return validated_data
    
    def generate_predictions(self) -> Dict[str, Any]:
        """Generate professional predictions with full diagnostics"""
        logger.info("Starting professional prediction generation")
        
        try:
            # 1. Calculate base xG with uncertainty
            home_xg, home_uncertainty = self.xg_calculator.calculate_base_xg(
                self.data['home_goals'], self.data['home_conceded'], True, self.data['league']
            )
            away_xg, away_uncertainty = self.xg_calculator.calculate_base_xg(
                self.data['away_goals'], self.data['away_conceded'], False, self.data['league']
            )
            
            # 2. Apply evidence-based context factors
            home_xg_adj, home_uncertainty_adj = self.xg_calculator.apply_context_factors(
                home_xg, home_uncertainty, self.data['home_injuries'],
                self.data['home_motivation'], self.data.get('home_goals_home', 0)
            )
            away_xg_adj, away_uncertainty_adj = self.xg_calculator.apply_context_factors(
                away_xg, away_uncertainty, self.data['away_injuries'], 
                self.data['away_motivation'], self.data.get('away_goals_away', 0)
            )
            
            # 3. Run professional simulation
            home_goals, away_goals = self.simulator.simulate_match(
                home_xg_adj, away_xg_adj, home_uncertainty_adj, away_uncertainty_adj
            )
            
            # 4. Calculate probabilities
            probs = self.simulator.calculate_probabilities(
                home_goals, away_goals, self.data['league']
            )
            
            # 5. Analyze market edges
            market_odds = self.data.get('market_odds', {})
            edges = self.market_analyzer.calculate_edges(probs, market_odds)
            
            # 6. Sensitivity analysis
            sensitivity_results = self.sensitivity_analyzer.analyze_robustness(
                home_xg_adj, away_xg_adj, edges, self.data['league']
            )
            
            # 7. Generate betting recommendations
            recommendations = self._generate_betting_recommendations(
                probs, edges, market_odds, sensitivity_results
            )
            
            # 8. Analyze match context (DESCRIPTIVE ONLY)
            context = self.context_analyzer.analyze_context(
                home_xg_adj, away_xg_adj,
                self.data.get('home_tier', 'MEDIUM'),
                self.data.get('away_tier', 'MEDIUM'), 
                self.data.get('home_goals_home', 0),
                self.data.get('away_goals_away', 0),
                self.data['league']
            )
            
            # 9. Generate diagnostics
            diagnostics = self._generate_diagnostics(
                probs, edges, sensitivity_results, context
            )
            
            # 10. Compile final results
            results = self._compile_results(
                probs, edges, recommendations, context, diagnostics,
                home_xg, away_xg, home_xg_adj, away_xg_adj
            )
            
            logger.info("Professional prediction generation completed successfully")
            return results
            
        except Exception as e:
            logger.error(f"Prediction generation failed: {str(e)}")
            raise
    
    def _generate_betting_recommendations(self, probs: Dict[str, float], edges: Dict[str, float],
                                        market_odds: Dict[str, float], sensitivity_results: Dict[str, Any]) -> List[BettingRecommendation]:
        """Generate professional betting recommendations with guardrails"""
        
        recommendations = []
        bankroll = self.data.get('bankroll', 1000)
        league = self.data['league']
        min_edge = LEAGUE_PARAMS.get(league, LEAGUE_PARAMS['default'])['min_edge']
        
        # Market mappings
        market_mappings = [
            ('home_win', '1x2_home', 'Home Win'),
            ('away_win', '1x2_away', 'Away Win'), 
            ('draw', '1x2_draw', 'Draw'),
            ('btts_yes', 'btts_yes', 'BTTS Yes'),
            ('btts_no', 'btts_no', 'BTTS No'),
            ('over_25', 'over_25', 'Over 2.5 Goals'),
            ('under_25', 'under_25', 'Under 2.5 Goals')
        ]
        
        for prob_key, odds_key, market_name in market_mappings:
            model_prob = probs.get(prob_key, 0.0)
            market_odd = market_odds.get(odds_key, 2.0)
            edge = edges.get(prob_key, 0.0)
            
            # Check minimum edge requirement
            if abs(edge) < min_edge:
                continue
            
            # Get robustness
            robustness_data = sensitivity_results['robust_edges'].get(
                prob_key, sensitivity_results['fragile_edges'].get(prob_key, {})
            )
            robustness = robustness_data.get('robustness', 'LOW')
            passes_sensitivity = robustness in ['HIGH', 'MEDIUM']
            
            # Calculate stake
            stake = self.staking_calculator.calculate_kelly_stake(
                model_prob, market_odd, bankroll, league, robustness
            )
            
            # Skip zero-stake recommendations
            if stake <= 0:
                continue
            
            # Generate explanation
            explanation = self._generate_recommendation_explanation(
                market_name, model_prob, market_odd, edge, robustness
            )
            
            recommendation = BettingRecommendation(
                market=market_name,
                model_prob=model_prob,
                market_odds=market_odd,
                implied_prob=1.0/market_odd if market_odd > 0 else 0.0,
                edge=edge,
                recommended_stake=stake,
                confidence='HIGH' if robustness == 'HIGH' else 'MEDIUM',
                robustness=robustness,
                explanation=explanation,
                passes_sensitivity=passes_sensitivity
            )
            
            recommendations.append(recommendation)
        
        # Sort by edge size
        recommendations.sort(key=lambda x: abs(x.edge), reverse=True)
        return recommendations
    
    def _generate_recommendation_explanation(self, market: str, model_prob: float, 
                                           odds: float, edge: float, robustness: str) -> List[str]:
        """Generate professional explanation for recommendations"""
        
        explanations = []
        
        explanations.append(
            f"Model probability: {model_prob:.1%} vs Market implied: {1.0/odds:.1%}"
        )
        explanations.append(f"Edge: {edge:+.1%} | Robustness: {robustness}")
        
        if robustness == 'HIGH':
            explanations.append("âœ… Edge survives sensitivity testing (Â±20% xG changes)")
        elif robustness == 'MEDIUM':
            explanations.append("âš ï¸ Edge moderately robust - consider reduced stake")
        else:
            explanations.append("âŒ Edge fragile - not recommended")
            
        if edge > 0.1:
            explanations.append("ðŸŽ¯ Strong value opportunity detected")
        elif edge > 0.05:
            explanations.append("ðŸ“ˆ Good value opportunity")
        else:
            explanations.append("ðŸ“Š Modest value - stake accordingly")
            
        return explanations
    
    def _generate_diagnostics(self, probs: Dict[str, float], edges: Dict[str, float],
                            sensitivity_results: Dict[str, Any], context: MatchContext) -> ModelDiagnostics:
        """Generate comprehensive model diagnostics"""
        
        # Data quality score
        data_quality = self._calculate_data_quality()
        
        # Calibration score (proxy)
        total_prob = probs['home_win'] + probs['draw'] + probs['away_win']
        calibration_score = 100 * (1 - abs(total_prob - 1.0))
        
        # Market alignment
        market_alignment = self._calculate_market_alignment(probs)
        
        # Uncertainty score
        uncertainty_score = 100 - (context.confidence_score * 0.8)
        
        # Sensitivity result
        sensitivity_passed = sensitivity_results['overall_robustness'] == 'HIGH'
        
        # Recommended action
        if len(sensitivity_results['robust_edges']) > 0:
            recommended_action = "CONFIDENT_BETTING"
        elif len(sensitivity_results['robust_edges']) + len(sensitivity_results['fragile_edges']) > 0:
            recommended_action = "CAUTIOUS_BETTING" 
        else:
            recommended_action = "NO_VALUE"
        
        return ModelDiagnostics(
            data_quality_score=data_quality,
            calibration_score=calibration_score,
            market_alignment=market_alignment,
            uncertainty_score=uncertainty_score,
            sensitivity_passed=sensitivity_passed,
            recommended_action=recommended_action
        )
    
    def _calculate_data_quality(self) -> float:
        """Calculate data quality score"""
        score = 70.0  # Base score
        
        # Form data
        if self.data.get('home_goals', 0) > 0 and self.data.get('away_goals', 0) > 0:
            score += 10
            
        # Recent form data
        if self.data.get('home_goals_home', 0) > 0 or self.data.get('away_goals_away', 0) > 0:
            score += 8
            
        # H2H data
        h2h_data = self.data.get('h2h_data', {})
        if h2h_data.get('matches', 0) >= 3:
            score += 12
            
        return min(100.0, score)
    
    def _calculate_market_alignment(self, probs: Dict[str, float]) -> float:
        """Calculate market alignment score"""
        # This would compare model probs to market-implied probs
        # For now, using a simplified version
        total_xg = (probs['over_25'] * 3.5 + probs['under_25'] * 1.5)  # Approximate
        
        # Market-implied total goals (approximate from odds)
        market_odds = self.data.get('market_odds', {})
        over_odds = market_odds.get('over_25', 2.0)
        under_odds = market_odds.get('under_25', 1.8)
        
        if over_odds > 0 and under_odds > 0:
            market_implied_over = 1.0 / over_odds
            market_implied_under = 1.0 / under_odds
            total_implied = market_implied_over + market_implied_under
            market_over_prob = market_implied_over / total_implied
            market_total_xg = market_over_prob * 3.5 + (1 - market_over_prob) * 1.5
            
            alignment = 100 * (1 - min(1.0, abs(total_xg - market_total_xg) / 2.0))
            return alignment
        
        return 75.0  # Default alignment
    
    def _compile_results(self, probs: Dict[str, float], edges: Dict[str, float],
                        recommendations: List[BettingRecommendation], context: MatchContext,
                        diagnostics: ModelDiagnostics, raw_home_xg: float, raw_away_xg: float,
                        adj_home_xg: float, adj_away_xg: float) -> Dict[str, Any]:
        """Compile final professional results"""
        
        return {
            'match_info': {
                'match': f"{self.data['home_team']} vs {self.data['away_team']}",
                'league': self.data['league'],
                'timestamp': datetime.now().isoformat()
            },
            'expected_goals': {
                'raw': {'home': raw_home_xg, 'away': raw_away_xg},
                'adjusted': {'home': adj_home_xg, 'away': adj_away_xg},
                'total': adj_home_xg + adj_away_xg
            },
            'probabilities': {
                'match_outcomes': {
                    'home_win': probs['home_win'],
                    'draw': probs['draw'], 
                    'away_win': probs['away_win']
                },
                'both_teams_score': {
                    'yes': probs['btts_yes'],
                    'no': probs['btts_no']
                },
                'over_under': {
                    'over_15': probs['over_15'],
                    'over_25': probs['over_25'],
                    'over_35': probs['over_35'],
                    'under_25': probs['under_25']
                },
                'exact_scores': probs['exact_scores']
            },
            'market_analysis': {
                'edges': edges,
                'recommendations': [
                    {
                        'market': rec.market,
                        'model_prob': rec.model_prob,
                        'market_odds': rec.market_odds,
                        'implied_prob': rec.implied_prob,
                        'edge': rec.edge,
                        'recommended_stake': rec.recommended_stake,
                        'confidence': rec.confidence,
                        'robustness': rec.robustness,
                        'explanation': rec.explanation,
                        'passes_sensitivity': rec.passes_sensitivity
                    }
                    for rec in recommendations
                ]
            },
            'match_context': {
                'primary_pattern': context.primary_pattern,
                'quality_gap': context.quality_gap,
                'home_advantage_amplified': context.home_advantage_amplified,
                'away_scoring_issues': context.away_scoring_issues,
                'confidence_score': context.confidence_score,
                'expected_tempo': context.expected_tempo
            },
            'diagnostics': {
                'data_quality_score': diagnostics.data_quality_score,
                'calibration_score': diagnostics.calibration_score,
                'market_alignment': diagnostics.market_alignment,
                'uncertainty_score': diagnostics.uncertainty_score,
                'sensitivity_passed': diagnostics.sensitivity_passed,
                'recommended_action': diagnostics.recommended_action
            },
            'professional_metadata': {
                'model_version': '3.0.0_professional',
                'calibration_level': 'EVIDENCE_BASED',
                'risk_profile': 'CONSERVATIVE',
                'timestamp': datetime.now().isoformat()
            }
        }

# =============================================================================
# PROFESSIONAL TEST FUNCTION
# =============================================================================

def test_professional_engine():
    """Test the professional prediction engine"""
    
    test_data = {
        'home_team': 'Tottenham Hotspur',
        'away_team': 'Chelsea', 
        'league': 'premier_league',
        'home_goals': 8,
        'away_goals': 4,
        'home_conceded': 6,
        'away_conceded': 7,
        'home_goals_home': 6,
        'away_goals_away': 1,
        'home_injuries': 2,
        'away_injuries': 2,
        'home_motivation': 'Normal',
        'away_motivation': 'Normal',
        'home_tier': 'STRONG',
        'away_tier': 'STRONG',
        'market_odds': {
            '1x2_home': 3.10,
            '1x2_draw': 3.40,
            '1x2_away': 2.30,
            'over_25': 1.80,
            'under_25': 2.00,
            'btts_yes': 1.90,
            'btts_no': 1.90
        },
        'bankroll': 1000,
        'h2h_data': {
            'matches': 4,
            'home_wins': 0,
            'away_wins': 1, 
            'draws': 3,
            'home_goals': 7,
            'away_goals': 9
        }
    }
    
    engine = ProfessionalPredictionEngine(test_data)
    results = engine.generate_predictions()
    
    print("ðŸŽ¯ PROFESSIONAL PREDICTION ENGINE TEST")
    print("=" * 70)
    print(f"Match: {results['match_info']['match']}")
    print(f"League: {results['match_info']['league']}")
    print(f"Expected Goals: {results['expected_goals']['adjusted']['home']:.2f} - {results['expected_goals']['adjusted']['away']:.2f}")
    print(f"Total xG: {results['expected_goals']['total']:.2f}")
    print(f"Home Win: {results['probabilities']['match_outcomes']['home_win']:.1%}")
    print(f"Draw: {results['probabilities']['match_outcomes']['draw']:.1%}")
    print(f"Away Win: {results['probabilities']['match_outcomes']['away_win']:.1%}")
    print(f"BTTS Yes: {results['probabilities']['both_teams_score']['yes']:.1%}")
    print(f"Over 2.5: {results['probabilities']['over_under']['over_25']:.1%}")
    print(f"Context: {results['match_context']['primary_pattern']}")
    print(f"Confidence: {results['match_context']['confidence_score']:.1f}%")
    
    print("\nðŸ’° BETTING RECOMMENDATIONS:")
    for rec in results['market_analysis']['recommendations']:
        print(f"- {rec['market']}: {rec['edge']:+.1%} edge | Stake: ${rec['recommended_stake']:.2f}")
    
    print(f"\nðŸ“Š DIAGNOSTICS:")
    print(f"Data Quality: {results['diagnostics']['data_quality_score']:.1f}/100")
    print(f"Market Alignment: {results['diagnostics']['market_alignment']:.1f}%")
    print(f"Recommended Action: {results['diagnostics']['recommended_action']}")

if __name__ == "__main__":
    test_professional_engine()
